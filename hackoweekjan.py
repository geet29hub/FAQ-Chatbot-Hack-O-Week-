# -*- coding: utf-8 -*-
"""hackoweekjan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tLN9yJK4ad_H_B-0z5Lg5TYjuy6tODXi
"""

!pip install nltk scikit-learn

import nltk
import string
import re

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab')

faq_data = {
    "What is admission process?": "You can apply online through the college portal.",
    "What is fee structure?": "Fee structure is available on the official website.",
    "What are hostel facilities?": "Separate hostels are available for boys and girls.",
    "What is exam timetable?": "Exam timetable is released one month before exams.",
    "How to contact administration?": "You can email admin@college.edu"
}

"""task 1"""

def basic_faq_responder(query):
    return faq_data.get(query, "Sorry, I don't have an answer for that.")

basic_faq_responder("What is fee structure?")

"""task 2"""

from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess(text):
    text = text.lower()
    text = re.sub(r'\d+', '', text)
    text = text.translate(str.maketrans('', '', string.punctuation))
    tokens = nltk.word_tokenize(text)
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return " ".join(tokens)

preprocess("What are the hostel facilities available?")

"""task 3

"""

from nltk.corpus import wordnet

def get_synonyms(word):
    synonyms = set()
    for syn in wordnet.synsets(word):
        for lemma in syn.lemmas():
            synonyms.add(lemma.name())
    return synonyms

get_synonyms("fees")

"""task 4"""

questions = list(faq_data.keys())
answers = list(faq_data.values())

processed_questions = [preprocess(q) for q in questions]

vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(processed_questions)

def faq_tfidf_response(user_query):
    user_query = preprocess(user_query)
    user_vec = vectorizer.transform([user_query])
    similarity = cosine_similarity(user_vec, tfidf_matrix)
    index = similarity.argmax()
    return answers[index]

faq_tfidf_response("Tell me about hostel")

"""task 5"""

intent_data = {
    "admission": [
        "how to apply",
        "admission process",
        "how can I get admission"
    ],
    "fees": [
        "fee structure",
        "how much fees",
        "college fees"
    ],
    "hostel": [
        "hostel facility",
        "is hostel available",
        "boys hostel"
    ],
    "exam": [
        "exam schedule",
        "exam timetable",
        "when are exams"
    ],
    "contact": [
        "contact admin",
        "college phone number",
        "how to contact"
    ]
}

X = []
y = []

for intent, phrases in intent_data.items():
    for phrase in phrases:
        X.append(preprocess(phrase))
        y.append(intent)

model = Pipeline([
    ('tfidf', TfidfVectorizer()),
    ('classifier', MultinomialNB())
])

model.fit(X, y)

def predict_intent(query):
    query = preprocess(query)
    return model.predict([query])[0]

predict_intent("How much is the college fee?")

def chatbot(query):
    intent = predict_intent(query)

    if intent == "admission":
        return faq_data["What is admission process?"]
    elif intent == "fees":
        return faq_data["What is fee structure?"]
    elif intent == "hostel":
        return faq_data["What are hostel facilities?"]
    elif intent == "exam":
        return faq_data["What is exam timetable?"]
    elif intent == "contact":
        return faq_data["How to contact administration?"]
    else:
        return "Sorry, I couldn't understand your query."

while True:
    user_input = input("You: ")
    if user_input.lower() == "exit":
        break
    print("Bot:", chatbot(user_input))